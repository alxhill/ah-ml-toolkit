{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9848d5e5-7a7d-4d25-ab33-fdee7342b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e7e8cc-6e70-49e0-be83-49802b9a9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db5db0a-7010-43a9-90c2-1acda4d6de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = models.AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11d6518-75c3-45a8-be7b-48aabdb0b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /Users/alxhill/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057935d91e104cf39cc59c013f0ae669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/171M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rn = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec183a64-725d-4b7a-8ae4-8324bd62b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39bb650e-1c95-4513-b48f-888f153fce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"../data/raw/living_room/living.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0121987-1f62-473a-81d8-01b95a515bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proc = preprocess(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6349c18-44da-40e8-b4f9-5719d6051e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7762,  0.7762,  0.7762,  ...,  0.9988,  1.1187,  1.3070],\n",
       "         [ 0.8104,  0.8104,  0.8104,  ...,  1.2385,  1.3755,  1.4098],\n",
       "         [ 0.8961,  0.8789,  0.8789,  ...,  1.4098,  1.4098,  1.4098],\n",
       "         ...,\n",
       "         [-1.5185, -1.5185, -1.5185,  ...,  0.0912,  0.3823,  0.1597],\n",
       "         [-1.5870, -1.5870, -1.5870,  ..., -0.3027,  0.1083,  0.3138],\n",
       "         [-1.5699, -1.5528, -1.5699,  ..., -0.4739, -0.3198,  0.0741]],\n",
       "\n",
       "        [[ 0.6254,  0.6429,  0.6254,  ...,  0.7304,  0.8529,  1.0455],\n",
       "         [ 0.6779,  0.6779,  0.6779,  ...,  0.9405,  1.0805,  1.0980],\n",
       "         [ 0.7304,  0.7129,  0.7304,  ...,  1.1155,  1.0980,  1.0805],\n",
       "         ...,\n",
       "         [-1.6155, -1.5980, -1.5980,  ..., -0.6352, -0.4426, -0.6527],\n",
       "         [-1.6856, -1.6681, -1.6856,  ..., -0.9853, -0.6176, -0.4776],\n",
       "         [-1.6681, -1.6681, -1.6856,  ..., -1.1604, -1.0028, -0.6527]],\n",
       "\n",
       "        [[ 0.4439,  0.4439,  0.4265,  ...,  0.5659,  0.6531,  0.8274],\n",
       "         [ 0.4788,  0.4614,  0.4614,  ...,  0.7751,  0.8797,  0.8971],\n",
       "         [ 0.5311,  0.5136,  0.5311,  ...,  0.9319,  0.9319,  0.9145],\n",
       "         ...,\n",
       "         [-1.5081, -1.5081, -1.5081,  ..., -0.9330, -0.8633, -1.0724],\n",
       "         [-1.5430, -1.5256, -1.5256,  ..., -1.2119, -0.9853, -0.9330],\n",
       "         [-1.5256, -1.5256, -1.5256,  ..., -1.3339, -1.2293, -1.0376]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf427b1-eb71-4a0a-a000-3497ff49e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_t = torch.unsqueeze(img_proc, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb48b7e8-ad08-463f-b9b7-b02849a639f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.eval()\n",
    "out_t = rn(input_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89058f48-9cd5-4f9d-ab38-14030c1081e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/models/imagenet_classes.txt\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfefa175-2aa1-4a96-beb0-132cb2973a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = torch.max(out_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec7827cc-b3bf-475c-ac54-6459901217a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = torch.nn.functional.softmax(out_t, dim=1)[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f1f88c4-22aa-45c1-8510-efac8d0b565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('grand piano, grand', 40.70096969604492)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[idx[0]], pct[idx[0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6392b57-7423-4f2c-a2c4-f0b3135e5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sort_idx = torch.sort(out_t, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3216670c-71a9-46b9-970f-146865bca84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grand piano, grand', 40.70096969604492),\n",
       " ('window shade', 15.908583641052246),\n",
       " ('home theater, home theatre', 4.891425132751465),\n",
       " ('sliding door', 4.216376304626465),\n",
       " ('entertainment center', 1.4299015998840332)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(labels[i], pct[i].item()) for i in sort_idx[0][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e83fc8c-54c0-4a5e-977c-2edb2dd3f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/alxhill/.cache/torch/hub/isl-org_MiDaS_master\n",
      "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_hybrid_384.pt\" to /Users/alxhill/.cache/torch/hub/checkpoints/dpt_hybrid_384.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800b4046d4434fc69a618851067be66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "midas = torch.hub.load(\"isl-org/MiDaS\", \"DPT_Hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61ab02ab-25e5-4fd0-a540-0a11a2da16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/alxhill/.cache/torch/hub/isl-org_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "midas_transforms = torch.hub.load(\"isl-org/MiDaS\", \"transforms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c298e-5e77-4122-b38b-ed874b8d19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "midas.to(\"cpu\")\n",
    "midas.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d045b28-0eed-4ef3-b3b9-8f6bac79f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f6e27c0-3518-42d1-9c09-5934974c9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv = cv2.imread(\"../data/raw/living_room/living.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cebe4303-004f-48b6-8a03-0d7ecf3f8036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.2319e-01, -2.2239e-01, -1.9654e-01,  ...,  1.4698e-01,\n",
       "            1.3878e-01,  1.8534e-01],\n",
       "          [-1.8872e-01, -2.1714e-01, -1.9653e-01,  ...,  1.4369e-01,\n",
       "            1.6922e-01,  1.5970e-01],\n",
       "          [-2.2690e-01, -2.3234e-01, -2.0527e-01,  ...,  1.3164e-01,\n",
       "            1.4745e-01,  1.3676e-01],\n",
       "          ...,\n",
       "          [-7.9428e-01, -7.9817e-01, -8.1925e-01,  ..., -8.1719e-01,\n",
       "           -8.1464e-01, -7.6400e-01],\n",
       "          [-8.5181e-01, -7.7221e-01, -7.9221e-01,  ..., -8.2507e-01,\n",
       "           -7.5133e-01, -7.9474e-01],\n",
       "          [-7.8321e-01, -7.8093e-01, -8.4727e-01,  ..., -7.7913e-01,\n",
       "           -9.3948e-01, -7.9529e-01]],\n",
       "\n",
       "         [[-8.2015e-02, -8.1217e-02, -5.5365e-02,  ...,  3.5875e-01,\n",
       "            3.5054e-01,  3.9710e-01],\n",
       "          [-4.7548e-02, -7.5963e-02, -5.5356e-02,  ...,  3.5545e-01,\n",
       "            3.8098e-01,  3.7146e-01],\n",
       "          [-8.5725e-02, -9.1165e-02, -6.4093e-02,  ...,  3.5505e-01,\n",
       "            3.7086e-01,  3.6016e-01],\n",
       "          ...,\n",
       "          [-6.6806e-01, -6.4226e-01, -6.7845e-01,  ..., -6.4550e-01,\n",
       "           -6.6562e-01, -6.4110e-01],\n",
       "          [-7.0723e-01, -6.2876e-01, -6.3735e-01,  ..., -6.8689e-01,\n",
       "           -6.0126e-01, -6.3230e-01],\n",
       "          [-6.4203e-01, -6.3976e-01, -6.9004e-01,  ..., -6.3104e-01,\n",
       "           -7.9855e-01, -6.3017e-01]],\n",
       "\n",
       "         [[ 4.2600e-03,  5.0574e-03,  3.0910e-02,  ...,  5.7051e-01,\n",
       "            5.6231e-01,  6.0887e-01],\n",
       "          [ 3.8727e-02,  1.0311e-02,  3.0919e-02,  ...,  5.6722e-01,\n",
       "            5.9275e-01,  5.8323e-01],\n",
       "          [ 5.4968e-04, -4.8909e-03,  2.2182e-02,  ...,  5.6681e-01,\n",
       "            5.8262e-01,  5.7193e-01],\n",
       "          ...,\n",
       "          [-4.4061e-01, -3.9912e-01, -4.5136e-01,  ..., -3.6489e-01,\n",
       "           -3.7714e-01, -3.5784e-01],\n",
       "          [-4.6750e-01, -3.8562e-01, -3.9654e-01,  ..., -3.8410e-01,\n",
       "           -3.0935e-01, -3.3540e-01],\n",
       "          [-3.9889e-01, -3.9662e-01, -4.4690e-01,  ..., -3.3546e-01,\n",
       "           -5.0680e-01, -3.3213e-01]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    in_batch = midas_transforms.dpt_transform(img_cv).to(\"cpu\")\n",
    "    prediction = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd95eda-b6ce-4629-8613-5c2947ce6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
